import streamlit as st
import urllib.request
import json
import pandas as pd
import re
from datetime import datetime
from collections import Counter
from itertools import combinations

import plotly.express as px
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
import networkx as nx
from wordcloud import WordCloud
from matplotlib import font_manager
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os

# Streamlit Cloud í•œê¸€ í°íŠ¸ ì„¤ì •
FONT_PATH = "fonts/NotoSansCJKkr-Regular.otf"

if os.path.exists(FONT_PATH):
    font_prop = fm.FontProperties(fname=FONT_PATH)
    plt.rcParams["font.family"] = font_prop.get_name()

plt.rcParams["axes.unicode_minus"] = False


############################################
# í˜ì´ì§€ ì„¤ì •
############################################
st.set_page_config(
    page_title="ğŸ˜ˆKíŒ ë°ëª¬ í—Œí„°ìŠ¤ğŸ˜ˆ íŒ¬ë¤ í˜•ì„±ì˜ í•µì‹¬ ìš”ì¸",
    layout="wide"
)

st.markdown("### C221090 ìµœì¬ì€")
st.title("KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ í˜•ì„±ì˜ í•µì‹¬ ìš”ì¸")

st.markdown("""
ì´ ëŒ€ì‹œë³´ë“œëŠ” **ë„¤ì´ë²„ ë‰´ìŠ¤ API**ë¥¼ í†µí•´ ìˆ˜ì§‘í•œ ê¸°ì‚¬ ì œëª© ë° ë³¸ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ  
*KíŒ ë°ëª¬ í—Œí„°ìŠ¤* íŒ¬ë¤ì´ **ì–´ë–¤ ìš”ì¸ì„ í†µí•´ í˜•ì„±ë˜ì—ˆëŠ”ì§€**ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
""")

st.sidebar.header("ë¶„ì„ ì„¤ì •")

article_limit = st.sidebar.slider(
    "ë¶„ì„ì— ì‚¬ìš©í•  ê¸°ì‚¬ ìˆ˜",
    min_value=100,
    max_value=1000,
    step=100,
    value=1000
)

############################################
# ë„¤ì´ë²„ API ì„¤ì • (Streamlit Secrets)
############################################
client_id = st.secrets["naver"]["client_id"]
client_secret = st.secrets["naver"]["client_secret"]

display_count = 100
num_data = 1000
sort = "date"
query = urllib.parse.quote("kíŒ ë°ëª¬ í—Œí„°ìŠ¤")

############################################
# ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
############################################
@st.cache_data
def fetch_news():
    results = []
    for idx in range(1, num_data + 1, display_count):
        url = (
            "https://openapi.naver.com/v1/search/news?"
            f"query={query}&start={idx}&display={display_count}&sort={sort}"
        )
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)

        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            data = json.loads(response.read().decode("utf-8"))
            results.extend(data["items"])
    return results

with st.spinner("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
    results = fetch_news()

############################################
# ë°ì´í„°í”„ë ˆì„ ìƒì„±
############################################
remove_tags = re.compile(r"<.*?>")
df = pd.DataFrame([
    {
        "pubDate": datetime.strptime(item["pubDate"], "%a, %d %b %Y %H:%M:%S +0900"),
        "title": re.sub(remove_tags, "", item["title"]),
        "description": re.sub(remove_tags, "", item["description"]),
    }
    for item in results
])

# ğŸ”— ê¸°ì‚¬ ìˆ˜ ìœ„ì ¯ ì—°ê²°
df = df.iloc[:article_limit]

st.success(f"ì´ ë¶„ì„ ê¸°ì‚¬ ìˆ˜: {len(df)}")

############################################
# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
############################################
text_title = " ".join(df["title"].tolist())

def cleanString(text):
    pattern = r"[ã„±-ã…ã…-ã…£]+"
    text = re.sub(pattern, "", text)
    pattern = r"<[^>]*>"
    text = re.sub(pattern, "", text)
    pattern = r"[^\w\s\n]"
    text = re.sub(pattern, "", text)
    return text

text_title = cleanString(text_title)


# í˜•íƒœì†Œ ë¶„ì„ê¸° ëŒ€ì‹  ì •ê·œì‹ ê¸°ë°˜ í† í°í™”
words_morphs = re.findall(r"[ê°€-í£]{2,}", text_title)

############################################
# ë¶ˆìš©ì–´ ë¡œë“œ
############################################
with open("data/korean_stopwords.txt", encoding="utf-8") as f:
    stopwords = set(f.read().splitlines())

# ì›Œë“œ í´ë¼ìš°ë“œì—ì„œ ë‹¨ì–´ë¥¼ í™•ì¸í•´ë³´ë‹ˆ ì œëª© ì¤„ì„ë§, ì œëª© ê´€ë ¨ ë‹¨ì–´, ê¸°ìì˜ ë§ìŠµê´€ê°™ì€ ë‹¨ì–´ê°€ í¬í•¨ë¼ ì£¼ì œì™€ ë§ì§€ ì•ŠëŠ” ë‹¨ì–´ë¥¼ ë¶ˆìš©ì–´ë¡œ íŒë‹¨.
stop_str = """
ì¼€ë°í—Œ ë°ëª¬ í—Œí„°ìŠ¤ ì¼€ì´íŒ K íŒ KíŒ quot amp lt
ì–´ì©” ì–´ì©” ìˆ˜ê°€ ì–´ì©”ìˆ˜ê°€
ì€ ëŠ” ì— ê°€ ì„ ë¥¼ ì˜ ë„ ë˜í•œ ë” ìœ„í•´
"""
stopwords.update(stop_str.split())

words = [w for w in words_morphs if w not in stopwords]

############################################
######## AI ì½”ë“œ ì°¸ì¡° (ê·¸ë˜í”„ ìƒì„± ë¶€ë¶„) ########
############################################
st.subheader("1ï¸âƒ£ ë‰´ìŠ¤ ì œëª© ìµœë¹ˆ ë‹¨ì–´ ë¶„ì„")

top_n = st.sidebar.selectbox(
    "ìµœë¹ˆ ë‹¨ì–´ ê°œìˆ˜ ì„ íƒ",
    options=[10, 20, 30],
    index=1
)

vocab = Counter(words)
df_top = pd.DataFrame(vocab.most_common(top_n), columns=["word", "count"])

fig = px.bar(
    df_top,
    x="count",
    y="word",
    orientation="h",
    text="count",
    title=f"ë‰´ìŠ¤ ì œëª© ìµœë¹ˆ ë‹¨ì–´ TOP {top_n}",
    color="count",
    color_continuous_scale="Blues"
)

fig.update_layout(yaxis=dict(categoryorder="total ascending"))
st.plotly_chart(fig, use_container_width=True)

st.markdown(""" 
            #### :orange[ë‰´ìŠ¤ ì œëª© ìµœë¹ˆ ë‹¨ì–´ ë¶„ì„ í•´ì„] 
            ë³¸ ê·¸ë˜í”„ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ê´€ë ¨ ë‰´ìŠ¤ ì œëª©ì—ì„œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ë‹¨ì–´ ìƒìœ„ 20ê°œë¥¼ ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ ì‹œê°í™”í•œ ê²°ê³¼ì´ë‹¤. 
            ê°€ì¥ ë†’ì€ ë¹ˆë„ë¥¼ ë³´ì¸ ë‹¨ì–´ëŠ” **â€˜ç¾(ë¯¸êµ­)â€™**, **â€˜ê³¨ë“ ê¸€ë¡œë¸Œâ€™**, **â€˜í›„ë³´â€™**, **â€˜2025â€™** ë“±ìœ¼ë¡œ, ì‘í’ˆì´ êµ­ë‚´ ì´ìŠˆë¥¼ ë„˜ì–´ **ë¯¸êµ­ ë° ê¸€ë¡œë²Œ ì‹œìƒì‹ ë§¥ë½ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ê³  ìˆìŒ**ì„ ë³´ì—¬ì¤€ë‹¤. 
            ì´ëŠ” í•´ë‹¹ ì‘í’ˆì´ ë‹¨ìˆœí•œ ì½˜í…ì¸  ì†Œë¹„ ëŒ€ìƒì´ ì•„ë‹ˆë¼ **êµ­ì œì  ì„±ê³¼ì™€ ë¹„êµì˜ ëŒ€ìƒ**ìœ¼ë¡œ ì¸ì‹ë˜ê³  ìˆìŒì„ ì‹œì‚¬í•œë‹¤. ë˜í•œ **â€˜ì»¬ì²˜â€™, â€˜ì½˜í…ì¸ â€™, â€˜ìœ íŠœë¸Œâ€™, â€˜ì¸ê¸°â€™**ì™€ ê°™ì€ ë‹¨ì–´ì˜ ë¹ˆë²ˆí•œ ë“±ì¥ì€ ì‘í’ˆì´ í•˜ë‚˜ì˜ ì˜ìƒë¬¼ì— ê·¸ì¹˜ì§€ ì•Šê³  **í™•ì¥ ê°€ëŠ¥í•œ ë¬¸í™” ì½˜í…ì¸ ë¡œ ì†Œë¹„Â·ì¬ìƒì‚°ë˜ê³  ìˆìŒ**ì„ ì˜ë¯¸í•œë‹¤. 
            íŠ¹íˆ ìœ íŠœë¸Œì™€ ê°™ì€ í”Œë«í¼ ì–¸ê¸‰ì€ íŒ¬ë¤ì´ 2ì°¨ ì°½ì‘, ë¦¬ë·°, ë¦¬ì•¡ì…˜ ë“±ì„ í†µí•´ ëŠ¥ë™ì ìœ¼ë¡œ í™•ì¥ë˜ê³  ìˆìŒì„ ì•”ì‹œí•œë‹¤. 
            
            ì¢…í•©í•˜ë©´, ì´ ë¹ˆë„ ë¶„í¬ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ì˜ íŒ¬ë¤ í˜•ì„±ì´ 1. ê¸€ë¡œë²Œ ì„±ê³¼ ë‹´ë¡ ê³¼ 2. ë¬¸í™”/í”Œë«í¼ ì¤‘ì‹¬ì˜ í™•ì‚° êµ¬ì¡°ë¥¼ í†µí•´ ë™ì‹œì— ê°•í™”ë˜ì—ˆìŒì„ ë³´ì—¬ì£¼ëŠ” ì§€í‘œë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. """) 

st.divider()

############################################
# ì„±ê³¼, ì¸ì • ì„œì‚¬ (Altair)
############################################
selected_achievement_keywords = st.sidebar.multiselect(
    "ì„±ê³¼Â·ì¸ì • í‚¤ì›Œë“œ ì„ íƒ",
    options=["ìˆ˜ìƒ", "í›„ë³´", "ê³¨ë“ ê¸€ë¡œë¸Œ", "ìƒ", "ì„±ê³¼"],
    default=["ìˆ˜ìƒ", "í›„ë³´", "ê³¨ë“ ê¸€ë¡œë¸Œ"]
)

def count_achievement(title):
    return sum(1 for k in selected_achievement_keywords if k in title)

df["achievement_count"] = df["title"].apply(count_achievement)

df_daily = (
    df.groupby(pd.Grouper(key="pubDate", freq="D"))["achievement_count"]
    .sum()
    .reset_index()
)

chart = (
    alt.Chart(df_daily)
    .mark_area(interpolate="monotone", opacity=0.8)
    .encode(
        x="pubDate:T",
        y="achievement_count:Q",
        tooltip=["pubDate:T", "achievement_count:Q"],
    )
)

st.altair_chart(chart, use_container_width=True)

st.markdown(
    """ #### :orange[ì„±ê³¼ ë° ì¸ì • ì„œì‚¬ì˜ ì‹œê°„ë³„ ë³€í™” í•´ì„] 
    ì´ ê·¸ë˜í”„ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ê´€ë ¨ ë‰´ìŠ¤ ì œëª©ì—ì„œ **â€˜ìˆ˜ìƒâ€™, â€˜í›„ë³´â€™, â€˜ê³¨ë“ ê¸€ë¡œë¸Œâ€™ ë“± ì„±ê³¼, ì¸ì • í‚¤ì›Œë“œê°€ ì‹œê°„ì— ë”°ë¼ ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í–ˆëŠ”ì§€**ë¥¼ ì‹œê³„ì—´ë¡œ ë‚˜íƒ€ë‚¸ ê²°ê³¼ì´ë‹¤. 
    ì´ˆê¸° êµ¬ê°„ì—ì„œëŠ” ì„±ê³¼ ê´€ë ¨ í‚¤ì›Œë“œì˜ ë“±ì¥ ë¹ˆë„ê°€ ë¹„êµì  ë‚®ê²Œ ìœ ì§€ë˜ë‹¤ê°€, **12ì›” ì´ˆ íŠ¹ì • ì‹œì ì„ ê¸°ì ìœ¼ë¡œ ê¸‰ê²©í•œ í”¼í¬ê°€ í˜•ì„±ë˜ëŠ” í˜„ìƒ**ì´ ê´€ì°°ëœë‹¤. ì´ëŠ” ì‘í’ˆì´ êµ­ì œ ì‹œìƒì‹ í›„ë³´ ì§€ëª… í˜¹ì€ ìˆ˜ìƒ ì†Œì‹ê³¼ í•¨ê»˜ ì§‘ì¤‘ì ì¸ ë¯¸ë””ì–´ ì£¼ëª©ì„ ë°›ì•˜ìŒì„ ì‹œì‚¬í•œë‹¤. 
    
    íŠ¹íˆ ë‹¨ê¸°ê°„ì— ë†’ì€ ë¹ˆë„ë¡œ ì„±ê³¼, ì¸ì • ì„œì‚¬ê°€ ë°˜ë³µ ë…¸ì¶œë˜ë©´ì„œ ì‘í’ˆì— ëŒ€í•œ **ëŒ€ì¤‘ì  ì‹ ë¢°ì™€ ìƒì§• ìë³¸ì´ ê°•í™”ë˜ì—ˆê³ **, ì´ëŠ” ê¸°ì¡´ íŒ¬ì¸µì„ ë„˜ì–´ ìƒˆë¡œìš´ ì ì¬ íŒ¬ì˜ ìœ ì…ì„ ì´‰ì§„í•˜ëŠ” í•µì‹¬ ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. 
    ì¦‰, í•´ë‹¹ ì‹œê³„ì—´ íŒ¨í„´ì€ *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ì˜ íŒ¬ë¤ í˜•ì„±ì´ ë‹¨ìˆœí•œ ì½˜í…ì¸  ì†Œë¹„ê°€ ì•„ë‹Œ **ì™¸ë¶€ ì„±ê³¼ë¥¼ í†µí•œ â€˜ì¸ì •ì˜ ì„œì‚¬â€™ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í™•ì‚°ë˜ì—ˆìŒ**ì„ ë³´ì—¬ì¤€ë‹¤. """) 

st.divider()

############################################ # ê¸€ë¡œë²Œ ì •ì²´ì„± (Seaborn) ############################################ 
st.subheader("3ï¸âƒ£ ê¸€ë¡œë²Œ ì •ì²´ì„± í”„ë ˆì„ê³¼ íŒ¬ë¤ í™•ì¥") 
global_keywords = ["ë¯¸êµ­", "ê¸€ë¡œë²Œ", "í•´ì™¸", "ê³¨ë“ ê¸€ë¡œë¸Œ"]
df["global_identity"] = df["title"].apply(lambda x: int(any(k in x for k in global_keywords))) 
identity_summary = pd.DataFrame({ "frame": ["ê¸€ë¡œë²Œ ì •ì²´ì„±"], "count": [df["global_identity"].sum()] }) 
############################################ ######## AI ì½”ë“œ ì°¸ì¡° (ê·¸ë˜í”„ ìƒì„± ë¶€ë¶„) ######## ############################################ 
fig2, ax = plt.subplots() 
sns.barplot(data=identity_summary, x="frame", y="count", ax=ax) 
ax.set_title("ê¸€ë¡œë²Œ ì •ì²´ì„± í”„ë ˆì„ ë“±ì¥ ë¹ˆë„") 
st.pyplot(fig2)

st.markdown(
    """ #### :orange[ê¸€ë¡œë²Œ ì •ì²´ì„± í”„ë ˆì„ê³¼ íŒ¬ë¤ í™•ì¥ í•´ì„] 
    ì´ ê·¸ë˜í”„ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ê´€ë ¨ ë‰´ìŠ¤ ì œëª©ì—ì„œ **ê¸€ë¡œë²Œ ì •ì²´ì„± í”„ë ˆì„**(ë¯¸êµ­, í•´ì™¸, ê³¨ë“ ê¸€ë¡œë¸Œ ë“±)ê³¼ **êµ­ë‚´ ì •ì²´ì„± í”„ë ˆì„**(í•œêµ­, êµ­ë‚´ ë“±)ì´ ê°ê° ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í–ˆëŠ”ì§€ë¥¼ ë¹„êµí•œ ê²°ê³¼ì´ë‹¤. 
    
    ë¶„ì„ ê²°ê³¼, ê¸€ë¡œë²Œ ì •ì²´ì„± í”„ë ˆì„ì´ êµ­ë‚´ ì •ì²´ì„± í”„ë ˆì„ë³´ë‹¤ **í˜„ì €íˆ ë†’ì€ ë¹ˆë„ë¡œ ë“±ì¥**í•˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” í•´ë‹¹ ì‘í’ˆì´ í•œêµ­ ì½˜í…ì¸ ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ë¯¸ë””ì–´ ë‹´ë¡  ì†ì—ì„œëŠ” **â€˜êµ­ë‚´ ì‘í’ˆâ€™ë³´ë‹¤ëŠ” â€˜ê¸€ë¡œë²Œ ì„±ê³¼ë¥¼ ì´ë£¬ ì½˜í…ì¸ â€™ë¡œ ë” ê°•í•˜ê²Œ í˜¸ëª…ë˜ê³  ìˆìŒ**ì„ ì˜ë¯¸í•œë‹¤. 
    ì´ëŸ¬í•œ ë‹´ë¡  êµ¬ì¡°ëŠ” íŒ¬ë¤ í˜•ì„± ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. ê¸€ë¡œë²Œ ì„±ê³¼ì™€ í•´ì™¸ ì¸ì •ì„ ê°•ì¡°í•˜ëŠ” í”„ë ˆì„ì€ ì‘í’ˆì— ëŒ€í•œ **ìƒì§•ì  ê°€ì¹˜ì™€ ì‹ ë¢°ë„ë¥¼ ê°•í™”**í•˜ë©°, ê¸°ì¡´ íŒ¬ë¿ ì•„ë‹ˆë¼ ìƒˆë¡œìš´ ì ì¬ íŒ¬ì—ê²Œë„ â€œì£¼ëª©í•  ë§Œí•œ ì½˜í…ì¸ â€ë¼ëŠ” ì¸ì‹ì„ ì œê³µí•œë‹¤. 
    
    ì¦‰, *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ì˜ íŒ¬ë¤ í™•ì¥ì€ êµ­ë‚´ ì •ì²´ì„±ì— ê¸°ë°˜í•œ ì‘ì›ë³´ë‹¤ëŠ” **ê¸€ë¡œë²Œ ë¬´ëŒ€ì—ì„œì˜ ì¸ì •ê³¼ ì„±ì·¨ë¥¼ ë§¤ê°œë¡œ í•œ í™•ì¥ ì „ëµ**ì— ë” í¬ê²Œ ì˜ì¡´í•˜ê³  ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ê²°ê³¼ë¼ í•  ìˆ˜ ìˆë‹¤. """) 
st.divider()


############################################
# ì›Œë“œí´ë¼ìš°ë“œ
############################################
st.subheader("4ï¸âƒ£ í•µì‹¬ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")

wc_colormap = st.sidebar.selectbox(
    "ì›Œë“œí´ë¼ìš°ë“œ ìƒ‰ìƒ í…Œë§ˆ",
    options=["coolwarm", "viridis", "plasma", "Blues"],
    index=0
)

text_for_wc = " ".join(words)

FONT_PATH = "fonts/NotoSansCJKkr-Regular.ttf"

wc = WordCloud(
    font_path=FONT_PATH,
    background_color="black",
    colormap=wc_colormap,
    max_words=50,
    collocations=False  ############# AI ì½”ë“œ ì°¸ì¡°(collocations ë¶€ë¶„) #############
).generate(text_for_wc)


fig3, ax3 = plt.subplots(figsize=(10,5))
ax3.imshow(wc)
ax3.axis("off")
st.pyplot(fig3)

st.markdown(
    """ #### :orange[í•µì‹¬ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ í•´ì„] 
    ì›Œë“œí´ë¼ìš°ë“œëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ê´€ë ¨ ë‰´ìŠ¤ ì œëª©ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë¹ˆë„ì— ë”°ë¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•œ ê²°ê³¼ë¡œ, **ë‹¨ì–´ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ë“±ì¥ ë¹ˆë„ê°€ ë†’ìŒì„ ì˜ë¯¸í•œë‹¤.** 
    ê°€ì¥ ë‘ë“œëŸ¬ì§€ê²Œ ë‚˜íƒ€ë‚œ í‚¤ì›Œë“œëŠ” **â€˜ç¾(ë¯¸êµ­)â€™**, **â€˜ê³¨ë“ ê¸€ë¡œë¸Œâ€™**, **â€˜ì–´ì›Œì¦ˆâ€™**, **â€˜í›„ë³´â€™** ë“±ìœ¼ë¡œ, ì‘í’ˆì´ êµ­ë‚´ ë‹´ë¡ ì— ë¨¸ë¬´ë¥´ì§€ ì•Šê³  **ê¸€ë¡œë²Œ ì‹œìƒì‹ê³¼ êµ­ì œì  ì„±ê³¼ì˜ ë§¥ë½ ì†ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ í˜¸ëª…ë˜ê³  ìˆìŒ**ì„ ë³´ì—¬ì¤€ë‹¤. 
    ì´ëŠ” íŒ¬ë¤ í˜•ì„±ì´ ì‘í’ˆì˜ ì™„ì„±ë„ë¿ë§Œ ì•„ë‹ˆë¼ **ì™¸ë¶€ë¡œë¶€í„°ì˜ ê³µì‹ì  ì¸ì •ê³¼ ìƒì§• ìë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°•í™”ë˜ì—ˆìŒ**ì„ ì‹œì‚¬í•œë‹¤. 
    
    ë˜í•œ **â€˜ì½˜í…ì¸ â€™, â€˜ì»¬ì²˜â€™, â€˜OSTâ€™, â€˜ìœ íŠœë¸Œâ€™**ì™€ ê°™ì€ ë‹¨ì–´ë“¤ì€ ì‘í’ˆì´ í•˜ë‚˜ì˜ ì˜ìƒë¬¼ì— ê·¸ì¹˜ì§€ ì•Šê³  ìŒì•…, ì˜ìƒ í”Œë«í¼, 2ì°¨ ì°½ì‘ ë“±ìœ¼ë¡œ **í™•ì¥ ê°€ëŠ¥í•œ ë¬¸í™” ì½˜í…ì¸ ë¡œ ì†Œë¹„ë˜ê³  ìˆìŒ**ì„ ë“œëŸ¬ë‚¸ë‹¤. 
    ì´ëŠ” íŒ¬ë¤ì´ ìˆ˜ë™ì ì¸ ì‹œì²­ìë¥¼ ë„˜ì–´ ëŠ¥ë™ì ìœ¼ë¡œ ì°¸ì—¬í•˜ê³  ì¬ìƒì‚°í•˜ëŠ” ì§‘ë‹¨ìœ¼ë¡œ í˜•ì„±ë˜ì—ˆìŒì„ ì˜ë¯¸í•œë‹¤. 
    
    ê²°ë¡ ì ìœ¼ë¡œ, ì›Œë“œí´ë¼ìš°ë“œëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ì˜ íŒ¬ë¤ í˜•ì„±ì´ 1. ê¸€ë¡œë²Œ ì„±ê³¼ì— ëŒ€í•œ ì¸ì • ì„œì‚¬ì™€ 2. í”Œë«í¼ ê¸°ë°˜ ë¬¸í™” í™•ì‚° êµ¬ì¡°ê°€ ê²°í•©ëœ ê²°ê³¼ì„ì„ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì  ìš”ì•½ì´ë¼ í•  ìˆ˜ ìˆë‹¤. """)

st.divider()
############################################
# í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
############################################
st.subheader("5ï¸âƒ£ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")

min_edge_count = st.sidebar.slider(
    "ë„¤íŠ¸ì›Œí¬ ì—£ì§€ ìµœì†Œ ë¹ˆë„",
    min_value=5,
    max_value=50,
    step=5,
    value=20
)

descriptions = df["description"].tolist()
normalize_map = {"ìŠ¤ì¼€": "ìŠ¤ì¼€ì¼"}

all_nouns = []
for text in descriptions:
    text_cleaned = re.sub(r"[^ê°€-í£\s]", "", text)
    nouns = re.findall(r"[ê°€-í£]{2,}", text_cleaned)
    nouns = [w for w in set(nouns) if len(w) > 1 and w not in stopwords]
    nouns = [normalize_map.get(w, w) for w in nouns]
    all_nouns.append(nouns)

edge_list = []
for nouns in all_nouns:
    edge_list.extend(combinations(sorted(nouns), 2))

edge_counts = Counter(edge_list)
filtered_edges = {e: w for e, w in edge_counts.items() if w >= min_edge_count}

G = nx.Graph()
for (n1, n2), w in filtered_edges.items():
    G.add_edge(n1, n2, weight=w)

pos = nx.spring_layout(G, seed=42)
fig4, ax4 = plt.subplots(figsize=(14,14))

nx.draw_networkx(
    G,
    pos,
    ax=ax4,
    node_size=[G.degree(n)*100 for n in G.nodes()],
    width=[G[u][v]["weight"]*0.05 for u,v in G.edges()],
    font_family="AppleGothic",
    node_color="skyblue",
    edge_color="gray"
)

ax4.set_title("KíŒ ë°ëª¬ í—Œí„°ìŠ¤ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬")
ax4.axis("off")
st.pyplot(fig4)

st.markdown(""" #### :orange[í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í•´ì„] ë³¸ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ í•¨ê»˜ ë“±ì¥í•œ í‚¤ì›Œë“œ ìŒì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•í•œ **ê³µë™ ì¶œí˜„(co-occurrence) ë„¤íŠ¸ì›Œí¬**ì´ë‹¤. 
            
            ë…¸ë“œëŠ” í•µì‹¬ í‚¤ì›Œë“œë¥¼, ì—£ì§€ëŠ” ë™ì¼ ê¸°ì‚¬ ë‚´ì—ì„œ í•¨ê»˜ ì–¸ê¸‰ëœ ê´€ê³„ë¥¼ ì˜ë¯¸í•˜ë©°, ë…¸ë“œì˜ í¬ê¸°ì™€ ì—£ì§€ì˜ ë‘ê»˜ëŠ” ê°ê° **ì—°ê²° ì •ë„ì™€ ë™ì‹œ ì¶œí˜„ ë¹ˆë„**ë¥¼ ë°˜ì˜í•œë‹¤. 
            ì¤‘ì•™ë¶€ì— ë°€ì§‘ëœ í‚¤ì›Œë“œ êµ°ì§‘ì„ ë³´ë©´ **â€˜ê³¨ë“ ê¸€ë¡œë¸Œâ€™, â€˜í›„ë³´â€™, â€˜ìˆ˜ìƒâ€™, â€˜ë¯¸êµ­â€™, â€˜ê¸€ë¡œë²Œâ€™, â€˜ì½˜í…ì¸ â€™, â€˜ë„·í”Œë¦­ìŠ¤â€™** ë“±ì´ ê°•í•˜ê²Œ ì—°ê²°ë˜ì–´ ë‚˜íƒ€ë‚˜ëŠ”ë°, ì´ëŠ” ì•ì„  ë¶„ì„ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ *KíŒ ë°ëª¬ í—Œí„°ìŠ¤* ë‹´ë¡ ì´ **ê¸€ë¡œë²Œ ì„±ê³¼ì™€ ê³µì‹ì  ì¸ì • ì„œì‚¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”ë˜ì–´ ìˆìŒì„** ë³´ì—¬ì¤€ë‹¤. 
            
            í•œí¸, ë„¤íŠ¸ì›Œí¬ì˜ ì£¼ë³€ë¶€ì—ëŠ” ì‘í’ˆ ìì²´ë¥¼ ë„˜ì–´ **ë‹¤ë¥¸ ì½˜í…ì¸  ë° ì•„í‹°ìŠ¤íŠ¸ì™€ì˜ ì—°ê²° ì§€ì **ì´ ê´€ì°°ëœë‹¤. 
            ì²« ë²ˆì§¸ ë„¤íŠ¸ì›Œí¬ ì´ë¯¸ì§€ì˜ ì™¼ìª½ ìƒë‹¨ì— ìœ„ì¹˜í•œ **â€˜í­ì‹¹â€“ìˆ˜ë‹¤â€™ ë…¸ë“œ ìŒ**ì€ ë„·í”Œë¦­ìŠ¤ ì˜¤ë¦¬ì§€ë„ ì½˜í…ì¸ ì¸ *ã€Œí­ì‹¹ ì†ì•˜ìˆ˜ë‹¤ã€*ë¥¼ ê°€ë¦¬í‚¤ëŠ” í‚¤ì›Œë“œë¡œ, *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ê°€ ë™ì¼ í”Œë«í¼ ë‚´ ë‹¤ë¥¸ í™”ì œì‘ê³¼ í•¨ê»˜ ì–¸ê¸‰ë˜ë©° **ë„·í”Œë¦­ìŠ¤ ë¸Œëœë“œ ì½˜í…ì¸  êµ°ì§‘ ì•ˆì—ì„œ ì†Œë¹„ë˜ê³  ìˆìŒì„** ì‹œì‚¬í•œë‹¤. 
            ë˜í•œ ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ë¶„ë¦¬ë˜ì–´ ë‚˜íƒ€ë‚œ **â€˜ìŠ¤íŠ¸â€“ë ˆì´â€“í‚¤ì¦ˆâ€™ í‚¤ì›Œë“œ êµ°ì§‘**ì€ KíŒ ë‚¨ì ì•„ì´ëŒ ê·¸ë£¹ *ìŠ¤íŠ¸ë ˆì´ í‚¤ì¦ˆ(Stray Kids)*ì™€ì˜ í˜‘ì—…ì„ ì˜ë¯¸í•œë‹¤. ì´ëŠ” ë³¸ ì‘í’ˆì´ ì• ë‹ˆë©”ì´ì…˜ ì½˜í…ì¸ ì— ê·¸ì¹˜ì§€ ì•Šê³ , ì‹¤ì œ KíŒ ì•„í‹°ìŠ¤íŠ¸ì™€ì˜ í˜‘ì—…ì„ í†µí•´ **ê¸°ì¡´ KíŒ íŒ¬ë¤ê³¼ êµì°¨ ì—°ê²°ë˜ëŠ” í™•ì¥ ì „ëµì„ ì·¨í•˜ê³  ìˆìŒì„** ë³´ì—¬ì¤€ë‹¤. 
            
            ë‘ ë²ˆì§¸ ì„œí˜ëŸ¬ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”ì—ì„œëŠ” ì´ëŸ¬í•œ í‚¤ì›Œë“œë“¤ì´ ë”ìš± ì´˜ì´˜í•˜ê²Œ ì—°ê²°ëœ êµ¬ì¡°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, 
            ì´ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ê°€ 1. ê¸€ë¡œë²Œ ì‹œìƒì‹ ë‹´ë¡  2. ë„·í”Œë¦­ìŠ¤ í”Œë«í¼ ë‚´ ì½˜í…ì¸  êµ°ì§‘ 3. KíŒ ì•„í‹°ìŠ¤íŠ¸ í˜‘ì—… ë„¤íŠ¸ì›Œí¬ ë¼ëŠ” ì„¸ ê°€ì§€ ì¶•ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë³µí•©ì ì¸ íŒ¬ë¤ í˜•ì„± êµ¬ì¡°ë¥¼ ê°–ê³  ìˆìŒì„ ì¢…í•©ì ìœ¼ë¡œ ë“œëŸ¬ë‚¸ë‹¤. 
            
            ê²°ê³¼ì ìœ¼ë¡œ ì´ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” *KíŒ ë°ëª¬ í—Œí„°ìŠ¤*ì˜ íŒ¬ë¤ì´ ë‹¨ì¼ ì‘í’ˆ ì¤‘ì‹¬ì´ ì•„ë‹ˆë¼ **í”Œë«í¼, ê¸€ë¡œë²Œ ì„±ê³¼, KíŒ ì‚°ì—… ì „ë°˜ê³¼ì˜ ì—°ê²°ì„ í†µí•´ í™•ì¥ë˜ëŠ” ë‹¤ì¸µì  êµ¬ì¡°**ì„ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë¶„ì„ ê²°ê³¼ë¼ í•  ìˆ˜ ìˆë‹¤. """)
